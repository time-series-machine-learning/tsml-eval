{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bake off redux: a review and experimental evaluation of recent time series classification algorithms\n",
    "\n",
    "This is the webpage and repo package to support the paper \"Bake off redux: a review and experimental evaluation of recent time series classification algorithms\" submitted to Springer Machine Learning (ML).\n",
    "\n",
    "Our results files are stored [here](https://github.com/time-series-machine-learning/tsml-eval/tree/main/tsml_eval/publications/y2023/tsc_bakeoff/results).\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The 112 UCR archive datasets are available at [timeseriesclassification.com](http://www.timeseriesclassification.com/dataset.php).\n",
    "\n",
    "The 30 new datasets will be uploaded to the [timeseriesclassification.com](http://www.timeseriesclassification.com) website in due course. For now, we provide the following link:\n",
    "\n",
    "<https://drive.google.com/file/d/1T7-A8XQYISLg-Ne-9glAKXxGy4H8FrQV/view?usp=sharing>\n",
    "\n",
    "## Install\n",
    "\n",
    "To install the latest version of the package with up-to-date algorithms, run:\n",
    "\n",
    "    pip install tsml-eval\n",
    "\n",
    "To install the package at the time of publication, run:\n",
    "\n",
    "    pip install tsml-eval==0.1.0\n",
    "\n",
    "Not all estimator dependencies are installed by default. You can install these individually as required or use the following dependency groups when installing:\n",
    "\n",
    "    pip install tsml-eval[all_extras,deep_learning]\n",
    "\n",
    "To install dependency versions used at the time of publication, use the publication requirements.txt:\n",
    "\n",
    "    pip install -r tsml_eval/publications/2023/tsc_bakeoff/static_publication_reqs.txt\n",
    "\n",
    "## Usage\n",
    "\n",
    "### Command Line\n",
    "\n",
    "Run [run_experiments.py](https://github.com/time-series-machine-learning/tsml-eval/blob/main/tsml_eval/publications/y2023/tsc_bakeoff/run_experiments.py) with the following arguments:\n",
    "\n",
    "1. Path to the data directory\n",
    "\n",
    "2. Path to the results directory\n",
    "\n",
    "3. The name of the model to run (see [set_bakeoff_classifier.py](https://github.com/time-series-machine-learning/tsml-eval/blob/main/tsml_eval/publications/y2023/tsc_bakeoff/set_bakeoff_classifier.py), i.e. R-STSF, HC2, InceptionTime)\n",
    "\n",
    "4. The name of the problem to run\n",
    "\n",
    "5. The resample number to run (0 is base train/test split)\n",
    "\n",
    "i.e. to run ItalyPowerDemand using HIVE-COTE V2 on the base train/test split:\n",
    "\n",
    "    python tsml_eval/publications/2023/tsc_bakeoff/run_experiments.py data/ results/ HC2 ItalyPowerDemand 0\n",
    "\n",
    "### Exactly Reproducing Results\n",
    "\n",
    "To better compare to past results and publications, our results on the 112 UCR datasets use the randomly generated resamples from the Java [tsml](https://github.com/time-series-machine-learning/tsml-java) package. To use these resample with our code, a flag must be toggled in the experiments file main method and individual files for each resample must be present in the data directory. These resamples in .ts file format are available for download here:\n",
    "\n",
    "https://mega.nz/file/ViMDgCJT#Q70StCshEWFzT8CEN5y-TrB9W-W3tApfPqWWx-qbuUg - 112 UCR datasets using Java tsml resamples\n",
    "\n",
    "The 30 new datasets used in our experiments use the resampling available by default in our experiments file. An exception to this is ProximityForest, which is implemented in Java and uses the Java resampling as a result.\n",
    "\n",
    "### Java Classifier Implementations\n",
    "\n",
    "Three of the classifiers used in our comparison were implemented in Java due to a lack of Python implementations which function reliably and are capable of accurately reproducing published results. These classifiers are the ElasticEnsemble, ProximityForest and TS-CHIEF. We use the implementations from the Java [tsml](https://github.com/time-series-machine-learning/tsml-java) package from revisions where they are available. We make two jar files available for download which contain the implementations of these classifiers:\n",
    "\n",
    "https://drive.google.com/file/d/1oXxpSa5PT9sBuVAbt57TLMANv4TMEejI/view?usp=sharing - TS-CHIEF and ProximityForest\n",
    "\n",
    "https://drive.google.com/file/d/1Vmgg5u7SE2jmsakHVlxPxvT_AfaZ151e/view?usp=sharing - ElasticEnsemble\n",
    "\n",
    "These jar files can be run from the command line using the following commands similar to the above Python classifiers:\n",
    "\n",
    "    java -jar tsml-ee.jar -dp=data/ -rp=results/  -cn=\"FastEE\" -dn=\"ItalyPowerDemand\" -f=0\n",
    "\n",
    "or\n",
    "\n",
    "    java -jar tsml-forest.jar -dp=data/ -rp=results/ -cn=\"ProximityForest\" -dn=\"ItalyPowerDemand\" -f=0\n",
    "\n",
    "or\n",
    "\n",
    "    java -jar tsml-forest.jar -dp=data/ -rp=results/  -cn=\"TS-CHIEF\" -dn=\"ItalyPowerDemand\" -f=0\n",
    "\n",
    "### Using Classifiers\n",
    "\n",
    "Most of our classifiers are available in the `aeon` Python package.\n",
    "\n",
    "The classifiers used in our experiments extend the `scikit-learn` interface and can also be used like their estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from aeon.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tsml.datasets import load_minimal_chinatown\n",
    "\n",
    "from tsml_eval.estimators import SklearnToTsmlClassifier\n",
    "from tsml_eval.publications.y2023.tsc_bakeoff import _set_bakeoff_classifier\n",
    "from tsml_eval.utils.validation import is_sklearn_classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data can be loaded using whichever method is most convenient, but should be formatted as either a 3D numpy array of shape (n_samples, n_channels, n_timesteps) or a list of length (n_samples) containing 2D numpy arrays of shape (n_channels, n_timesteps).\n",
    "\n",
    "A function is available for loading from .ts files."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(20, 1, 24) (20,)\n",
      "(20, 1, 24) (20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[[ 573.,  375.,  301.,  212.,   55.,   34.,   25.,   33.,  113.,\n          143.,  303.,  615., 1226., 1281., 1221., 1081.,  866., 1096.,\n         1039.,  975.,  746.,  581.,  409.,  182.]],\n\n       [[ 394.,  264.,  140.,  144.,  104.,   28.,   28.,   25.,   70.,\n          153.,  401.,  649., 1216., 1399., 1249., 1240., 1109., 1137.,\n         1290., 1137.,  791.,  638.,  597.,  316.]],\n\n       [[ 603.,  348.,  176.,  177.,   47.,   30.,   40.,   42.,  101.,\n          180.,  401.,  777., 1344., 1573., 1408., 1243., 1141., 1178.,\n         1256., 1114.,  814.,  635.,  304.,  168.]],\n\n       [[ 428.,  309.,  199.,  117.,   82.,   43.,   24.,   64.,  152.,\n          183.,  408.,  797., 1288., 1491., 1523., 1460., 1365., 1520.,\n         1700., 1797., 1596., 1139.,  910.,  640.]],\n\n       [[ 372.,  310.,  203.,  133.,   65.,   39.,   27.,   36.,  107.,\n          139.,  329.,  651.,  990., 1027., 1041.,  971., 1104.,  844.,\n         1023., 1019.,  862.,  643.,  591.,  452.]]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load example classification dataset\n",
    "X_train, y_train = load_minimal_chinatown(\"TRAIN\")\n",
    "X_test, y_test = load_minimal_chinatown(\"TEST\")\n",
    "\n",
    "# data can be loaded from .ts files using the following function\n",
    "# from tsml.datasets import load_from_ts_file\n",
    "# X, y = load_from_ts_file(\"data/data.ts\")\n",
    "\n",
    "print(type(X_train), type(y_train))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "X_train[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classifiers can be built using the `fit` method and predictions can be made using `predict`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 2., 1., 2., 2., 1., 2.,\n       2., 2., 2.])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a TSF classifier and make predictions\n",
    "tsf = TimeSeriesForestClassifier(n_estimators=100, random_state=0)\n",
    "tsf.fit(X_train, y_train)\n",
    "tsf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`predict_proba` can be used to get class probabilities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.86, 0.14],\n       [0.76, 0.24],\n       [0.72, 0.28],\n       [0.98, 0.02],\n       [0.78, 0.22],\n       [0.85, 0.15],\n       [0.94, 0.06],\n       [0.85, 0.15],\n       [0.85, 0.15],\n       [0.79, 0.21],\n       [0.16, 0.84],\n       [0.12, 0.88],\n       [0.59, 0.41],\n       [0.19, 0.81],\n       [0.13, 0.87],\n       [0.97, 0.03],\n       [0.16, 0.84],\n       [0.03, 0.97],\n       [0.  , 1.  ],\n       [0.37, 0.63]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsf.predict_proba(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we run some of the classifiers from the publication and find the accuracy for them on our example dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.85, 0.9, 0.9, 0.85]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers = [\n",
    "    \"RDST\",\n",
    "    \"R-STSF\",\n",
    "    \"WEASEL-D\",\n",
    "    \"MultiROCKET-Hydra\",\n",
    "]\n",
    "\n",
    "accuracies = []\n",
    "for classifier_name in classifiers:\n",
    "    # Select a classifier by name, see set_bakeoff_classifier.py for options\n",
    "    classifier = _set_bakeoff_classifier(classifier_name, random_state=0)\n",
    "\n",
    "    # if it is a sklearn classifier, wrap it to work with time series data\n",
    "    if is_sklearn_classifier(classifier):\n",
    "        classifier = SklearnToTsmlClassifier(\n",
    "            classifier=classifier, concatenate_channels=True, random_state=0\n",
    "        )\n",
    "\n",
    "    # fit and predict\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "accuracies"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
